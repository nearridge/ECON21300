---
title: "Homework 3: Do Trivia Nerds Cheat?"
author: "Neeraj Sharma"
date: "05/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE}
library(tidyverse)
library(lubridate)
library(knitr)
library(kableExtra)
library(scales)
library(ggthemes)
library(glue)
library(RColorBrewer)
```

# Question 1: Clean data and report summary statistics of percent correct answers by year and round of the championship, as well as when these players are on the honor system. Provide hypotheses as to why these summary percentages might vary.

```{r include = FALSE}
raw <- read_csv("pset3.csv")

edited <- raw %>% 
  pivot_longer(
    c(-name, -year, -round, -merge, -numbercorrect, -honorsystemcorrect),
    names_to = "qno",
    values_to = "ans"
  ) %>%
  mutate(qno = as.numeric(str_remove_all(qno, "q"))) %>%
  mutate(honorsystemcorrect = na_if(honorsystemcorrect, -99))
```

In order to clean this data set, the first thing I do is convert it from a wide data structure to a tidy structure. Several relational variables like name, year, round, and honorsystemcorrect remain fixed, but I pivot questions vertically to make question number a unique variable. The second cleaning action I perform is I convert the data type of the question number column I just created by removing the "Q" at the beginning of each entry and coercing the datatype. The third modification I perform to clean the data is I coerce all "-99" observations in the `honorsystemcorrect` column to be NA. Often times, -99 is code for missing values.

With the cleaned data, I was able to get insight into the aggregate performance of competitors in each year. 

```{r echo = FALSE}
edited %>%
  group_by(year, round) %>%
  summarize(sample_size = n(), 
            mean(ans), 
            max = max(numbercorrect),
            min = min(numbercorrect),
            mean = mean(numbercorrect),
            sd = sd(numbercorrect)) %>%
  drop_na() %>%
  mutate(`mean(ans)` = percent(`mean(ans)`, accuracy = 0.1),
         mean = round(mean, digits = 2),
         sd = round(sd, digits = 2)) %>%
  ungroup() %>%
  pivot_wider(round, names_from = year, values_from = c(sample_size, `mean(ans)`, min, max, mean, sd)) %>%
  select(round, 
         sample_size_2018, `mean(ans)_2018`, min_2018, max_2018, mean_2018, sd_2018, 
         sample_size_2019, `mean(ans)_2019`, min_2019, max_2019, mean_2019, sd_2019) %>%
  kable("latex", booktabs = T, align = "r", caption = "Summary Statistics of Correct Answers by Year and Round of the Championship",
        col.names = c("Round", 
                      "N", "% Correct", "Min", "Max", "Mean", "St Dev", 
                      "N", "% Correct", "Min", "Max", "Mean", "St Dev")) %>%
  add_header_above(c(" ", "Questions Overall" = 2, "Individual Performance" = 4, "Questions Overall" = 2, "Individual Performance" = 4)) %>%
  add_header_above(c(" ", "2018" = 6, "2019" = 6)) %>%
  column_spec(1, border_right = T) %>%
  column_spec(7, border_right = T)%>%
  kable_styling(position = "center", latex_options = "hold_position")
```

```{r echo = FALSE}
edited %>%
  group_by(year, round) %>%
  summarize(mean_hnr_pct = mean(honorsystemcorrect, na.rm = TRUE),
            med = median(honorsystemcorrect, na.rm = TRUE),
            min = min(honorsystemcorrect, na.rm = TRUE),
            max = max(honorsystemcorrect, na.rm = TRUE)) %>%
  mutate(mean_hnr_pct = percent(mean_hnr_pct, accuracy = 0.1),
         med = percent(med, accuracy = 0.1),
         min = percent(min, accuracy = 0.1),
         max = percent(max, accuracy = 0.1)) %>%
  drop_na() %>%
  pivot_wider(id_cols = round, names_from = year, values_from = c(mean_hnr_pct, med, min, max)) %>%
  select(round, 
         mean_hnr_pct_2018, med_2018, min_2018, max_2018, 
         mean_hnr_pct_2019, med_2019, min_2019, max_2019) %>%
  kable("latex", booktabs = T, align = "r",
        caption = "Summary Statistics of Honor System Performance by Year and Round",
        col.names = c("Round", 
                      "Mean", "Median", "Min", "Max", 
                      "Mean", "Median", "Min", "Max")) %>%
  add_header_above(c(" ", "2018" = 4, "2019" = 4)) %>%
  column_spec(1, border_right = T) %>%
  column_spec(5, border_right = T) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

In general, people who made it to later stages in the competition scored better in the regular season. This makes sense because you would expect the elimination championship format to only yield players who were actually good at trivia. 

Across the board, however, the percentages in the championship were significantly lower than the percentages in the regular season. One reason this could be is that the questions were much harder, so people got them wrong more. Another reason could be that cheating was disallowed so people didn't have that added boost inflating their honor system scores. Furthermore, the questions asked in round could be poorly calibrated and skew in obscure directions because of the small sample size in the championship. This problem doesn't exist in the regular season because the number of questions is higher. Finally, the competitive, high pressure environment of the championship could cause some people to crack and slump dramatically in the championship.

# Question 2: In the first two championship rounds, estimate how difficult the championship questions are relative to the regular season questions for people who play honestly during the regular season. Suggest at least two strategies for coming up with such an estimate. Be extremely explicit about the assumptions for each of your strategies to yield truthful estimates. Given the likely violation of your assumptions, say whether your estimates overestimate or underestimate the true amounts of cheating.

In office hours with Eric on 5/18, there was some confusion about the interpretation of this question. I interpret this question to ask us to find two distinct methods of identifying cheaters and then to come up with way to identify the increase in question difficulty based on the subset of fair players.

I think this this approach to this question makes a lot of sense. In order to quantify the impact that a change has on a sample group, one needs to only change that variable and keep everything else as stable as possible. In this case, cheaters have two dimensions of change: they go from cheating to not cheating, and "easy" questions to "hard" questions. For fair players, they only have one dimension of change: they go from easy questions to hard questions. Because fair players only experience one type of shift, the difference between their honor system performance and championship performance has only one motivating factor, while the cheaters have two factors driving differences in their performance. 

Thus, identifying fair players is a vital and technical step to understanding how difficult these two phases of competition are. Once I have controlled for the participants' cheating tendencies, I can evaluate the magnitude and impact of the different types of questions in isolation.

I make two overarching assumptions that are reasonable, but I would like to formally state them just for completeness. 

1. I assume that people try as hard as possible in the championship rounds and that their performance there is closely representative of their true potential. 
2. I assume that people only cheat in ways that will improve their performance. This rules out Google giving people wrong answers more frequently than they would give wrong answers themselves.  

## Step 1: Identify Cheaters (Three Strategies)

### Approach 1: Superior regular season performance is evidence of cheating

One possible strategy to distinguish between cheaters and non-cheaters is by calculating each person's percentage of correct answers given in the first two rounds and comparing that number to their honor system answers. If we assume that their scores in live competition represent a firm upper limit on their ability, than any individual who performed better at home must have cheated. 

The assumption that people who perform better at home than in competition cheat has several issues that cause this method to overestimate the amount of cheating. First, live competition is more stressful due to the stakes and pressure, so these external factors can impact performance. Second, this assumes that the sample selection in competition is equally suited for each person which is unlikely given the small sample size. In reality, any skew within the sample can cause the championship performance to drop slightly below the honor system performance. In summary, people could very reasonably under perform in the live round and not be cheaters. As a result, I believe this method will greatly overestimate the amount of cheating and greatly underestimate the difficulty of questions. 

### Approach 2: High honor system scores but low scores on easy championship questions is evidence of cheating

Honestly, if you are messing up on lots of easy questions, you are bad at trivia. People that are bad at trivia but appear to be good at trivia over a large sample size must regularly cheat. Thus, if I can identify people that fail to properly answer even the easiest questions in competition but have high success rates at home, they must have cheated at home.

One assumption I make is that there is a large enough sample of easy questions in rounds 1 and 2 of 2018 and 2019 that are perceived to be equally easy by all participants. Because all players have high accuracy on the honor system which spans questions of all difficulties, I expect that truthful players will answer easy questions correctly while cheating players will fail. I am unable to evaluate the cheating-ness of occasional cheaters because medium difficulty championship questions do not have the same filtering effect. Good players and bad players alike can fail on medium questions, but only bad players will fail on easy questions. This is why I only analyse failure rates on easy questions. Second, I assume that only those who under perform on easy questions cheat which rules out an entire class of people who are decent at trivia, but still cheat. This relates to the previous point, but has the effect that it means I remove potential cheaters from consideration. 

Because I am unable to analyze "decent" players with this method (of which some percentage cheat), I will overestimate the amount of cheating with this method. 

### Approach 3: Segment population into cheaters and fair players via T-Testing

An optimal strategy is to identify people whose play differs (statistically) significantly in the tournament from their play on the honor system. Specifically, I segment people by performing a one-tailed one-sample t-test for every individual. This t-test is one tailed because I am only interested in people who perform significantly worse in the championship than at home. Superior performance in the championship compared to performance at home is legitimate due to the live broadcast. I perform a one-sample t-test because I assume that the number of questions they answer at home is sufficiently large to approximate a population mean for that individual person. This is realistic, as Professor Levitt indicated that every participant had answered hundreds to thousands of questions at home during the regular season. In summary, these t-tests will tell us is if an individual's performance in competition is in line with their performance at home, or if their performance in competition is statistically significantly worse than their performance at home. 

I think this is the most accurate representation of the amount of cheating and difficulty of questions. However, I think this approach might slightly underestimate the amount of cheating because of how strong of a binary it creates between players. This assumes that players who play fairly play fairly 100% of the time and players who cheat also cheat 100% of the time. There are some work arounds I implement which I discuss later on to attempt to measure the intermediate amount of cheating, but as far as this approach goes mathematically, it only draws a concrete binary. The true distribution of cheaters is likely much more smooth than the one I construct, so I also then overestimate the true amount of cheating. 

## Step 2: Difficulty between championship questions relative to the regular season questions (1 Strategy)

As discussed above, fair players only experience one shift in going from the regular season to championship. Thus, any difference in the mean values of these two is only due to different types of questions, not the type of player they are. What this yields is a percentage difference between the questions in the championship and at home.

# Question 3: Report your findings from the strategies in question 2.

Hint: the most sensible way to report your findings would be a predicted value for the percent of questions you would predict each player have gotten correct over the first two rounds if they were not cheating in the regular season.

For each strategy you used, answer the following questions: 

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season? 
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
+ How many individual players can you say cheat with a high degree of confidence?

## Approach 1

Graphing all individuals by their correctness in the first two rounds and their honor system percentage allows us to visualize this model.

```{r echo = FALSE}
app1 <- edited %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, name, honorsystemcorrect) %>%
  summarize(pct_rt = mean(ans, na.rm = TRUE)) %>%
  drop_na() %>%
  mutate(cheater = if_else(honorsystemcorrect > pct_rt, 1, 0))

app1 %>%
  ggplot(aes(x = honorsystemcorrect, y = pct_rt, color = factor(cheater))) +
  geom_point() +
  geom_abline(slope = 1) +
  annotate("text", x = 0.65, y = 0.70, label = "Y = X", color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters, Approach 1",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))
```

Based on this partitioning of the data the mean percentage of correct answers given by honest players at home is `r app1 %>% filter(cheater == 0) %>% magrittr::use_series(honorsystemcorrect) %>% mean() %>% percent(accuracy = 0.1)` and the mean percentage of correct answers given by honest players in competition is `r app1 %>% filter(cheater == 0) %>% magrittr::use_series(pct_rt) %>% mean() %>% percent(accuracy = 0.1)`. This implies that the treatment effect of going from home questions to competition questions led to an increase in performance. Specifically, it implies that competition questions are **`r ((app1 %>% filter(cheater == 0) %>% magrittr::use_series(honorsystemcorrect) %>% mean()) - (app1 %>% filter(cheater == 0) %>% magrittr::use_series(pct_rt) %>% mean())) %>% percent(accuracy = 0.1)`** harder than home questions. That means they are actually easier. 

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season?
  + The `y = x` line provides an implicit upper limit on how one can score. If we accept the assumption that each person's championship score is representative of their true ability, then each individual's adjusted regular season score would be their championship score. The mean difference between the regular season and championship accuracy rate approximates the average percent of questions that are cheated on for the entire group during the regular season. That number is **`r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% pull(m) %>% mean(na.rm = TRUE) %>% percent(accuracy = 0.1)`**.
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
  + To find the percent of the players that cheat on at least 3% of the questions, I need to find the number of players who have a championship mean that is not within 3% of their honor system mean. I count `r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()` individuals who meet this criteria. That means that **`r (((app1 %>% nrow()) - (app1 %>% filter(cheater == 0) %>% nrow()) - (app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()))/(app1 %>% nrow())) %>% percent(accuracy = 0.1)`** percent of all players cheat on at least 3% of questions.
+ How many individual players can you say cheat with a high degree of confidence?
  + Because of how limited this approach is, it's impossible to distinguish between players that certainly and possibly cheat. A core assumption is that no player can over perform in the regular season, so because of how cut and dry that assumption is players that over perform are automatically labeled cheaters. Thus, **`r app1 %>% filter(cheater == 1) %>% nrow()`** players cheat according to this approach. 

## Approach 2

I calculate a "difficulty coefficient" for each question in the first two rounds of 2018 and 2019 by calculating the percentage of correct answers given, and then taking \frac{1}{\text{% Correct}}. This means that difficult questions are weighted more heavily than easy questions. Summing up the "difficulty coefficients" of each question a person gets right gives them a score of how good they are at trivia based on the assumption that good players get lots of hard questions right.

The next step is to quantify which questions are uniquely difficult. I calculate the mean and standard deviation of the correct percentage for each round in each year. Those questions that are 1 standard deviation above or below I denote as easier or harder, respectively. Players that fail easy questions likely cheated.

```{r echo = FALSE, message = FALSE}
champ_difficulty <- edited %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, round, qno) %>%
  summarize(corr = sum(ans), asked = n()) %>%
  mutate(pct_corr = corr/asked,
         # I let difficulty be 1/pct_corr because I want its value to be higher for questions that people get correct less often.
         difficulty_val = 1/pct_corr) %>%
  select(year, round, qno, pct_corr, difficulty_val)

# Difficult questions are answered correctly a standard deviation less frequently than the mean of each round.
champ_difficulty_metrics <- champ_difficulty %>%
  group_by(year, round) %>%
  summarize(mean_corr = mean(pct_corr), sd = sd(pct_corr))

best_nerds <- edited %>%
  drop_na(honorsystemcorrect) %>%
  filter(ans == 1) %>%
  inner_join(champ_difficulty) %>%
  group_by(name, honorsystemcorrect) %>%
  summarize(score = sum (difficulty_val)) %>%
  arrange(desc(score))
```

```{r echo = FALSE, message = FALSE}
full_qinfo <- champ_difficulty %>%
  left_join(champ_difficulty_metrics) %>%
  mutate(difficulty = if_else(pct_corr > mean_corr + sd, 0, 1),
         difficulty = if_else(pct_corr < mean_corr - sd, 2, difficulty))

full_qinfo %>%
  ggplot(mapping = aes(x = qno, y = pct_corr, fill = factor(difficulty))) +
  geom_col() +
  geom_hline(full_qinfo, mapping = aes(yintercept = mean_corr + sd), color = "#52b36c") +
  geom_hline(full_qinfo, mapping = aes(yintercept = mean_corr - sd), color = "#d15656") +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_fill_manual(name = "Question\n   Type",
                    labels = c("Easy", "Medium", "Hard"),
                    values = c("#52b36c", "#6d90c9", "#d15656")) +
  labs(title = "Difficulty of Questions by Round and Year, Approach 2",
       subtitle = "Bands are +/- 1 Standard Deviation from Mean",
       caption = "Source: LearnedLeague",
       x = "Question Number",
       y = "Percent Correct ") +
  facet_grid(round ~ year) +
  theme(plot.margin=unit(c(5.5, 5.5, 20, 5.5), "pt"),
        legend.direction = "horizontal",
        legend.position = c(0.15, -0.2),
        legend.background=element_blank())
```

Having identified which questions are easy and which are hard, I can perform analysis to understand how individuals perform on the easy questions versus their difficulty scores of all questions the answered correctly versus their honor system percentage to make predictions about who is cheating. 

```{r message = FALSE, echo = FALSE}
easyqs <- full_qinfo %>%
  filter(difficulty == 0) %>%
  select(year, round, qno)

small <- edited %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, name, honorsystemcorrect) %>%
  summarize(pct_rt = mean(ans, na.rm = TRUE)) %>%
  drop_na()

inner_join(easyqs, edited) %>%
  drop_na(honorsystemcorrect) %>%
  group_by(name, honorsystemcorrect) %>%
  summarize(count_corr_easyq = sum(ans)) %>%
  mutate(num_easyqs = nrow(easyqs),
         pct_easyqs = count_corr_easyq/num_easyqs) %>%
  select(-count_corr_easyq, -num_easyqs) %>%
  right_join(best_nerds) %>%
  mutate(honorsystemcorrect = percent(honorsystemcorrect, accuracy = 0.1),
         pct_easyqs = percent(pct_easyqs, accuracy = 0.1),
         score = round(score, digits = 3)) %>%
  arrange(-desc(score)) %>%
  head(5) %>%
  kable("latex", 
        booktabs = T, 
        caption = "Worst 5 Performers by Difficulty Score",
        col.names = c("Name", 
                      "% Correct, Honor", 
                      "% Correct, Easy Championship",
                      "Difficulty Score")) %>%
  kable_styling(position = "center", latex_options = "hold_position")

app2 <- inner_join(easyqs, edited) %>%
  drop_na(honorsystemcorrect) %>%
  group_by(name, honorsystemcorrect) %>%
  summarize(count_corr_easyq = sum(ans)) %>%
  mutate(num_easyqs = nrow(easyqs),
         pct_easyqs = count_corr_easyq/num_easyqs) %>%
  select(-count_corr_easyq, -num_easyqs) %>%
  right_join(best_nerds) %>%
  arrange(-desc(score))

app2 %>%
  ggplot(mapping = aes(x = score, y = pct_easyqs, color = honorsystemcorrect)) +
  geom_point() +
  scale_colour_viridis_c(name = " Honor System %",
                         option = "A",
                         labels = scales::label_percent(accuracy = 1)) +
  scale_x_log10() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = "% Easy Questions Answered by Score by Honor System %, Approach 2",
       caption = "Source: LearnedLeague",
       x = "Difficulty Score (log)",
       y = "Correctness of Easy Questions") +
  theme(plot.margin=unit(c(5.5, 5.5, 30, 5.5), "pt"),
        legend.direction = "horizontal",
        legend.background = element_rect(fill = "#e4e4e4"),
        legend.position = c(0.2, -0.2),
        legend.key.width = unit(25, "pt"),
        legend.key.height = unit(15, "pt"))


## being good at trivia means you can answer lots of hard questions.
```

I identify cheaters by selecting those who perform poorly on easy questions and overall given their stated percentage on the honor system.  

```{r message = FALSE, echo = FALSE}
app2_allplayers <- app2 %>% 
  group_by(pct_easyqs) %>%
  summarize(mean_hon = mean(honorsystemcorrect),
            sd_hon = sd(honorsystemcorrect),
            mean_score = mean(score),
            sd_score = sd(score)) %>%
  mutate(hon_upper = mean_hon + sd_hon,
         score_lower = mean_score - sd_score) %>%
  right_join(app2) %>%
  mutate(cheater = if_else(score_lower > score, 1, 0),
         cheater = if_else(honorsystemcorrect > hon_upper, 2, cheater),
         cheater = if_else(magrittr::and(score_lower > score, 
                                         honorsystemcorrect > hon_upper), 3, cheater),
         cheater = if_else(pct_easyqs > 0.5, 0, cheater),
         cheater = if_else(score > 30, 0, cheater),
         cheater = if_else(name == "VolkA", 3, cheater)) %>%
  select(name, honorsystemcorrect, pct_easyqs, 
         score, hon_upper, score_lower, cheater)

app2_cheaters <- app2_allplayers %>%
  filter(cheater != 0) %>%
  inner_join(small)

app2_fairplayers <- app2_allplayers %>%
  filter(cheater == 0) %>%
  inner_join(small)

ggplot() +
  geom_point(app2_cheaters, 
             mapping = aes(x = score, y = pct_easyqs, 
                           color = factor(cheater))) +
  geom_point(app2_fairplayers, mapping = aes(x = score, y = pct_easyqs), alpha = 0.1) +
  scale_color_manual(name = "Cheating ID Method",
                     labels = c("Score", "Honor System", "Both"),
                     values = c("#52b36c", "#6d90c9", "#d15656")) +
  scale_x_log10() +
  scale_y_continuous(limits = c(0, 1), 
                     labels = scales::label_percent()) +
 labs(title = "Distribution of Fair Players and Cheaters, Approach 2",
       caption = "Source: LearnedLeague",
       x = "Difficulty Score (log)",
       y = "Correctness of Easy Questions") +
  theme(legend.position = c(0.885, 0.175))
```

Based on this partitioning of the data, the mean percentage of correct answers given by honest players at home is `r app2_fairplayers %>% magrittr::use_series(honorsystemcorrect) %>% mean() %>% percent(accuracy = 0.1)` and the mean percentage of correct answers given by honest players in competition is `r app2_fairplayers %>% magrittr::use_series(pct_rt) %>% mean() %>% percent(accuracy = 0.1)`. This implies that competition questions are **`r ((app2_fairplayers %>% magrittr::use_series(honorsystemcorrect) %>% mean()) - (app2_fairplayers %>% magrittr::use_series(pct_rt) %>% mean())) %>% percent(accuracy = 0.1)`** harder than home questions. 

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season?
  + Based on this method, I project that `r app2_cheaters %>% mutate(m = honorsystemcorrect - pct_rt) %>% pull(m) %>% mean(na.rm = TRUE) %>% percent(accuracy = 0.1)` of questions were cheated on.
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
  + This approach grossly dichotomises players. It does a very poor job at evaluating how many questions people cheat on individually. I wouldn't recommend using this approach to answer this question, but for completeness's sake, I estimate that `r app2_cheaters %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m > 0.03) %>% nrow()` players cheat on 3% or more questions. 
+ How many individual players can you say cheat with a high degree of confidence?
  + Similarly, this approach does not distinguish well with confidence intervals. I estimate that `r app2_cheaters %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m > 0.03) %>% nrow()` cheated confidently. 

## Approach 3

```{r message = FALSE, include = FALSE}
ttester <- function(current_selection, year_sel) {
  obs <- edited %>%
    filter(round %in% c(1, 2), 
           year == year_sel,
           name == current_selection)
  # Case where people get a perfect score in competition returns no std dev so 
  # do not do a ttest in those situations
  if (sum(obs$ans) == 24) {
    return(1)
  }
  honsyscorr_num <- obs %>%
    magrittr::extract2(1,6)
  pval <- t.test(obs$ans, mu = honsyscorr_num, alternative = "less") %>%
    broom::tidy() %>%
    magrittr::extract2(1, 3)
}

pvals <- edited %>%
  drop_na(honorsystemcorrect, ans) %>%
  distinct(name, year) %>%
  mutate(pvals = map2(name, year, ttester),
         statsig = if_else(pvals < 0.05, 1, 0))

app3_allplayers <- edited %>%
  filter(round %in% c(1, 2)) %>%
  drop_na(honorsystemcorrect, ans) %>%
  group_by(year, name, honorsystemcorrect) %>%
  summarize(pct_rt = mean(ans)) %>%
  left_join(pvals) %>%
  mutate(cheater = if_else(statsig == 1, 1, 0))

# List of people that cheated
app3_cheaters <- app3_allplayers %>%
  filter(statsig == 1)

# List of people that didn't cheat
app3_fairplayers <- app3_allplayers %>%
  filter(statsig == 0) 
```

With this method, I run a t-test for every person to see if their performance in the championship could have come from their performance in the year. If their championship score was significantly worse, I identify them as a cheater. This is what that breakdown looks like with a dividing line plotted. 

```{r echo = FALSE}
# Point on the far right side scored 95% but scored in competition like someone who scored 80% on the honor system. Use that system to figure out what the predected scores of people should be. 

app3_allplayers %>%
  ggplot(mapping = aes(x = honorsystemcorrect, y = pct_rt, color = factor(cheater))) +
  geom_point() +
  geom_abline(slope = 1, color = "grey") +
  geom_abline(slope = 1.1, intercept = -0.25, color = "#6d90c9") +
  annotate("text", x = 0.65, y = 0.70, label = "Y = X", color = "black") +
  annotate("text", x = 0.665, y = 0.5, label = "Y = 1.1X - 0.25", color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters, Approach 3",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))

adj <- app3_allplayers %>%
  mutate(pred = if_else(cheater == 1, (pct_rt + 0.25)/1.1, honorsystemcorrect),
         diff = if_else(cheater == 1, honorsystemcorrect - pred, 0))
```

Based on this categorization, the mean correct answers given by honest players at home is `r mean(app3_fairplayers$honorsystemcorrect) %>% percent(accuracy = 0.1)` and in competition is `r mean(app3_fairplayers$pct_rt) %>% percent(accuracy = 0.1)`. Thus, the treatment effect of going from home to competition questions is **`r (mean(app3_fairplayers$honorsystemcorrect) - mean(app3_fairplayers$pct_rt)) %>% percent(accuracy = 0.1)`**. Competition questions **`r (mean(app3_fairplayers$honorsystemcorrect) - mean(app3_fairplayers$pct_rt)) %>% percent(accuracy = 0.1)`** harder. 

Showing the breakdown of accuracy by individual type shows that under this approach, fair players in the regular season actually fair much better in the postseason than cheaters. This make sense.

```{r message = FALSE, echo = FALSE, fig.height = 3.5}
bind_rows(app3_cheaters, app3_fairplayers) %>%
  inner_join(edited) %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, round, qno, cheater) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  ggplot(aes(x = qno, y = correct_ans/times_asked, group = cheater, fill = factor(cheater))) +
  geom_col(position = "dodge") +
  facet_grid(round ~ year) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_y_continuous(limits = c(0, 1), labels = label_percent()) +
  scale_fill_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "% correctly answered in Championship by Player Type, Approach 3", 
       caption = "Source: LearnedLeague",
       x = "Question Number", 
       y = "% Correctly Answered") +
  theme(legend.direction = "horizontal",
        legend.position = c(0.15, -0.15),
        legend.background=element_blank())
```

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season?
  + With this method, the `y = 1.1x - 0.25` line provides an implicit upper limit on how far away one's score can be in the regular season given their performance in the championship. If a person fails every question in the regular season but then gets a perfect score in the championship, this model predicts that the individual is actually more intelligent than their performance in the regular season would suggest. However, if a person gets 100% in the regular season then incorrectly answers every question in their championship, then they definitely cheated on 100% of questions. The mean difference between the adjusted regular season and championship accuracy rate approximates an upper limit on the percent of questions that are cheated on for the entire group during the regular season. That number is **`r adj %>% filter(cheater == 1) %>% pull(diff) %>% mean(na.rm = TRUE) %>% percent(accuracy = 0.1)`**. See Appendix 1 for more. 

+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
  + To find the percent of the players that cheat on at least 3% of the questions, I need to find the number of players who have a championship mean that is not within 3% of the upper limit line. There are `r (adj %>% filter(cheater == 1) %>% filter(diff < 0.03) %>% nrow())` players within 3% of the limit line and `r (adj %>% filter(cheater == 0) %>% nrow())` that are above the limit line. Thus, I believe that **`r (((adj %>% nrow()) - (adj %>% filter(cheater == 1) %>% filter(diff < 0.03) %>% nrow()) - (adj %>% filter(cheater == 0) %>% nrow()))/(adj %>% nrow())) %>% percent(accuracy = 0.1)`** of players cheat on at least 3% of all questions. Basically, most people cheat a little bit as evidenced by my answer to this question, but very rarely do people cheat a lot because that would drag my answer to the previous question up substantially. 
  
```{r include = FALSE}
pvals99 <- edited %>%
  drop_na(honorsystemcorrect, ans) %>%
  distinct(name, year) %>%
  mutate(pvals = map2(name, year, ttester),
         statsig = if_else(pvals < 0.01, 1, 0))
```

+ How many individual players can you say cheat with a high degree of confidence?
  + When I run this at a 95% confident interval, I get that **`r app3_cheaters %>% nrow()`** people cheated. If I increase this even further to 0.01 to get the highest of the high degree of confidence I get that **`r pvals99 %>% filter(statsig == 1) %>% nrow()`** individuals definitely cheated. 

# 4. Explain why it is easier or harder to make claims about the aggregate amount of cheating in a sample versus identifying individual cheaters.

Identifying individual cheaters was a relatively straight forward process. I propose one bad and two decent (in my opinion) strategies for separating cheaters from fair players in the data set. For individual cheaters, we are able to compare their personal scores to everyone else's scores. This allows us to do a sort of sample/population style statistical comparison. Being able to leverage the tendencies of the central limit theorem means that we are able to generate significantly more powerful predictions than without it. 

When we are evaluating the amount of cheating in the population as a whole, we are unable to substantively compare it to anything else. One could employ some form of folded cross-validation technique, but that is inappropriate here because of the lack of extensive honor system data beyond the mean. I'm unsure of the variance within an individual sample, but can get a general sense of it in the population. This means that it is very difficult to estimate the aggregate amount of cheating in a sample of the population compared to evaluating if an individual cheats or not. 

# 5. The players with -99 for honor code scores dropped out of the league after making one or both championships. Can you make any inferences about whether they cheated more or less than the players who have remained in the league, despite the fact you know nothing about their percent correct in the regular season?

I've identified the characteristics of what a cheater looks like so I can see what these people share in common with the cheaters. I constrain my answer to this question to only the the model I outline in Approach 3 because I believe that is the most robust approach. Using that model, I estimate that not a single person dropped out of the tournament was as a fair player. Not a single fair player had a similar percent of correct answers given which makes me believe that their data points would fall in the cheaters category. 

```{r echo = FALSE}
dropouts <- edited %>% 
  filter(is.na(honorsystemcorrect)) %>%
  distinct(name, year) %>%
  pull(name)

count_dropouts <- edited %>%
  filter(name %in% dropouts) %>%
  group_by(name, year) %>%
  summarize(pct_corr = mean(ans)) %>%
  ungroup() %>%
  count(pct_corr)

ggplot() +
  geom_abline(slope = 1, color = "grey") +
  annotate("text", x = 0.65, y = 0.70, label = "Y = X", color = "black") +

  geom_point(app3_allplayers, mapping = aes(honorsystemcorrect, pct_rt, color = factor(cheater)), alpha = 0.5) +
  geom_hline(count_dropouts, mapping = aes(yintercept = pct_corr), color = "#6d90c9") +
  labs(title = "Where do Competition Dropouts Fall? Compared to Approach 3.",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  theme(legend.direction = "horizontal",
        legend.position = c(0.12, -0.15),
        legend.background=element_blank())
```

# 6. The person who runs this league is interested in learning your findings. Create one visual that you think best would summarize your insights showing the amount/non-existence of cheating in his league.

I think the most straightforward visualization to model this is the modeling scatter plot I produce in the third approach. I include that again here. 

```{r echo = FALSE}
app3_allplayers %>%
  ggplot(mapping = aes(x = honorsystemcorrect, y = pct_rt, color = factor(cheater))) +
  geom_point() +
  geom_abline(slope = 1, color = "grey") +
  geom_abline(slope = 1.1, intercept = -0.25, color = "#6d90c9") +
  annotate("text", x = 0.65, y = 0.70, label = "Y = X", color = "black") +
  annotate("text", x = 0.665, y = 0.5, label = "Y = 1.1X - 0.25", color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters, Approach 3",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))
```

# Appendix

## 1

```{r echo = FALSE}
ggplot(adj, mapping = aes(pred, pct_rt, color = factor(cheater))) +
  geom_abline(slope = 1, color = "grey") +
  geom_abline(slope = 1.1, intercept = -0.25, color = "#6d90c9") +
  geom_point() +
  annotate("text", x = 0.25, y = 0.3, label = "Y = X", color = "black") +
  annotate("text", x = 0.29, y = 0.1, label = "Y = 1.1X - 0.25", color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Adjusted Distribution of Fair Players and Cheaters, Approach 3",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))
```
