---
title: "Homework 3: Do Trivia Nerds Cheat?"
author: "Neeraj Sharma"
date: "05/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE}
library(tidyverse)
library(lubridate)
library(knitr)
library(kableExtra)
library(scales)
library(ggthemes)
library(glue)
```

# Question 1: Clean data and report summary statistics of percent correct answers by year and round of the championship, as well as when these players are on the honor system. Provide hypotheses as to why these summary percentages might vary.

```{r include = FALSE}
raw <- read_csv("pset3.csv")

edited <- raw %>% 
  pivot_longer(
    c(-name, -year, -round, -merge, -numbercorrect, -honorsystemcorrect),
    names_to = "qno",
    values_to = "ans"
  ) %>%
  mutate(qno = as.numeric(str_remove_all(qno, "q"))) %>%
  mutate(honorsystemcorrect = na_if(honorsystemcorrect, -99))
```

In order to clean this data set, the first thing I do is convert it from a wide data structure to a tidy structure. Several relational variables like name, year, round, and honorsystemcorrect remain fixed, but I pivot questions vertically to make question number a unique variable. The second cleaning action I perform is I convert the data type of the question number column I just created by removing the "Q" at the beginning of each entry and coercing the datatype. The third modification I perform to clean the data is I coerce all "-99" observations in the `honorsystemcorrect` column to be NA. Often times, -99 is code for missing values.

With the cleaned data, I was able to get insight into the aggregate performance of competitors in each year. 

```{r echo = FALSE}
edited %>%
  group_by(year, round) %>%
  summarize(sample_size = n(), 
            mean(ans), 
            max = max(numbercorrect),
            min = min(numbercorrect),
            mean = mean(numbercorrect),
            sd = sd(numbercorrect)) %>%
  drop_na() %>%
  mutate(`mean(ans)` = percent(`mean(ans)`, accuracy = 0.1),
         mean = round(mean, digits = 2),
         sd = round(sd, digits = 2)) %>%
  ungroup() %>%
  pivot_wider(round, names_from = year, values_from = c(sample_size, `mean(ans)`, min, max, mean, sd)) %>%
  select(round, 
         sample_size_2018, `mean(ans)_2018`, min_2018, max_2018, mean_2018, sd_2018, 
         sample_size_2019, `mean(ans)_2019`, min_2019, max_2019, mean_2019, sd_2019) %>%
  kable("latex", booktabs = T, align = "r", caption = "Summary Statistics of Correct Answers by Year and Round of the Championship",
        col.names = c("Round", 
                      "N", "% Correct", "Min", "Max", "Mean", "St Dev", 
                      "N", "% Correct", "Min", "Max", "Mean", "St Dev")) %>%
  add_header_above(c(" ", "Questions Overall" = 2, "Individual Performance" = 4, "Questions Overall" = 2, "Individual Performance" = 4)) %>%
  add_header_above(c(" ", "2018" = 6, "2019" = 6)) %>%
  column_spec(1, border_right = T) %>%
  column_spec(7, border_right = T)%>%
  kable_styling(position = "center", latex_options = "hold_position")
```

In both years, the round to round percentage of questions answered correctly fluctuated

```{r echo = FALSE}
edited %>%
  group_by(year, round) %>%
  summarize(mean_hnr_pct = mean(honorsystemcorrect, na.rm = TRUE),
            med = median(honorsystemcorrect, na.rm = TRUE),
            min = min(honorsystemcorrect, na.rm = TRUE),
            max = max(honorsystemcorrect, na.rm = TRUE)) %>%
  mutate(mean_hnr_pct = percent(mean_hnr_pct, accuracy = 0.1),
         med = percent(med, accuracy = 0.1),
         min = percent(min, accuracy = 0.1),
         max = percent(max, accuracy = 0.1)) %>%
  drop_na() %>%
  pivot_wider(id_cols = round, names_from = year, values_from = c(mean_hnr_pct, med, min, max)) %>%
  select(round, 
         mean_hnr_pct_2018, med_2018, min_2018, max_2018, 
         mean_hnr_pct_2019, med_2019, min_2019, max_2019) %>%
  kable("latex", booktabs = T, align = "r",
        caption = "Summary Statistics of Honor System Performance by Year and Round",
        col.names = c("Round", 
                      "Mean", "Median", "Min", "Max", 
                      "Mean", "Median", "Min", "Max")) %>%
  add_header_above(c(" ", "2018" = 4, "2019" = 4)) %>%
  column_spec(1, border_right = T) %>%
  column_spec(5, border_right = T) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

# Question 2: In the first two championship rounds, estimate how difficult the championship questions are relative to the regular season questions for people who play honestly during the regular season. Suggest at least two strategies for coming up with such an estimate. Be extremely explicit about the assumptions for each of your strategies to yield truthful estimates. Given the likely violation of your assumptions, say whether your estimates overestimate or underestimate the true amounts of cheating.

In office hours with Eric on 5/18, there was some confusion about the interpretation of this question. I interpret this question to ask us to find two distinct methods of identifying cheaters and then to come up with way to identify the increase in question difficulty based on the subset of fair players.

I think this this approach to this question makes a lot of sense. In order to quantify the impact that a change has on a sample group, one needs to only change that variable and keep everything else as stable as possible. In this case, cheaters have two dimensions of change: they go from cheating to not cheating, and "easy" questions to "hard" questions. For fair players, they only have one dimension of change: they go from easy questions to hard questions. Because fair players only experience one type of shift, the difference between their honor system performance and championship performance has only one motivating factor, while the cheaters have two factors driving differences in their performance. 

Thus, identifying fair players is a vital and technical step to understanding how difficult these two phases of competition are. Once I have controlled for the participants' cheating tendencies, I can evaluate the magnitude and impact of the different types of questions in isolation.

I make two overarching assumptions that are resonable, but I would like to formally state them just for completeness. 

1. I assume that people try as hard as possible in the championship rounds and that their performance there is closely representative of their true potential. 
2. I assume that people only cheat in ways that will improve their performance. This rules out Google giving people wrong answers more frequently than they would give wrong answers themselves.  

## Step 1: Identify Cheaters (Three Strategies)

### Approach 1: Superior regular season performance is evidence of cheating

One possible strategy to distinguish between cheaters and non-cheaters is by calculating each person's percentage of correct answers given in the first two rounds and comparing that number to their honor system answers. If we assume that their scores in live competition represent a firm upper limit on their ability, than any individual who performed better at home must have cheated. 

The assumption that people who perform better at home than in competition cheat has several issues that cause this method to over estimate the amount of cheating. First, live competition is more stressful due to the stakes and pressure, so these external factors can impact performance. Second, this assumes that the sample selection in competition is equal to the questions at home. In summary, people could very resonably underperform in the live round and not be cheaters. As a result, I believe this method will greatly overestimate the amount of cheating and greatly underestimate the difficulty of questions. 

### Approach 2: High honor system scores but low scores on easy championship questions is evidence of cheating

Honestly, if you are messing up on lots of easy questions, you are bad at trivia. People that are bad at trivia but appear to be good at trivia over a large sample size must regularly cheat. Thus, if I can identify people that fail to properly answer even the easiest questions in competition properly but have high success rates at home, they must have cheated at home.



### Approach 3: Segment population into cheaters and fair players via T-Testing

An optimal strategy is to identify people whose play differs (statistically) significantly in the tournament from their play on the honor system. Specifically, I segment people by performing a one-tailed one-sample t-test for every individual. This t-test is one tailed because I am only interested in people who perform significantly worse in the championship than at home. Superior performance in the championship compared to performance at home is legitimate due to the live broadcast. I perform a one-sample t-test because I assume that the number of questions they answer at home is sufficiently large to approximate a population mean for that individual person. This is realistic, as Professor Levitt indicated that every participant had answered hundreds to thousands of questions at home during the regular season. In summary, these t-tests will tell us is if an individual's performance in competition is in line with their performance at home, or if their performance in competition is statistically significantly worse than their performance at home. 

## Step 2: Difficulty between championship questions relative to the regular season questions (1 Strategy)

As discussed above, fair players only experience one shift in going from the regular season to championship. Thus, any difference in the mean values of these two is only due to different types of questions, not the type of player they are. What this yields is a percentage difference between the questions in the championship and at home.

# Question 3: Report your findings from the strategies in from question 2.

Hint: the most sensible way to report your findings would be a predicted value for the percent of questions you would predict each player have gotten correct over the first two rounds if they were not cheating in the regular season.

For each strategy you used, answer the following questions: 

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season? 
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
+ How many individual players can you say cheat with a high degree of confidence?

## Approach 1

Graphing all individuals by their correctness in the first two rounds and their honor system percentage allows us to visualize this model.

```{r echo = FALSE}
app1 <- edited %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, name, honorsystemcorrect) %>%
  summarize(pct_rt = mean(ans, na.rm = TRUE)) %>%
  drop_na() %>%
  mutate(cheater = if_else(honorsystemcorrect > pct_rt, 1, 0))

app1 %>%
  ggplot(aes(x = honorsystemcorrect, y = pct_rt, color = factor(cheater))) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_text(aes(0.65, 0.70, label = "Y = X"), color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters under Approach 1",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))
```

Based on this partitioning of the data the mean percentage of correct answers given by honest players at home is `r app1 %>% filter(cheater == 0) %>% magrittr::use_series(honorsystemcorrect) %>% mean() %>% percent(accuracy = 0.1)` and the mean percentage of correct answers given by honest players in competition is `r app1 %>% filter(cheater == 0) %>% magrittr::use_series(pct_rt) %>% mean() %>% percent(accuracy = 0.1)`. This implies that the treatment effect of going from home questions to competition questions led to an increaes in performance. Specifically, it implies that competition questions are **`r ((app1 %>% filter(cheater == 0) %>% magrittr::use_series(honorsystemcorrect) %>% mean()) - (app1 %>% filter(cheater == 0) %>% magrittr::use_series(pct_rt) %>% mean())) %>% percent(accuracy = 0.1)`** harder than home questions. That means they are actually easier. 

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season?
  + The `y = x` line provides an implicit upper limit on how one can score. If we accept the assumption that each person's championship score is representative of their true ability, then each individual's adjusted regular season score would be their championship score. The mean difference between the regular season and championship accuracy rate approximates the average percent of questions that are cheated on for the entire group during the regular season. That number is **`r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% pull(m) %>% mean(na.rm = TRUE) %>% percent(accuracy = 0.1)`**.
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
  + To find the percent of the players that cheat on at least 3% of the questions, I need to find the number of players who have a championship mean that is not within 3% of their honor system mean. I count `r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()` individuals who meet this criteria. That means that **`r (((app1 %>% nrow()) - (app1 %>% filter(cheater == 0) %>% nrow()) - (app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()))/(app1 %>% nrow())) %>% percent(accuracy = 0.1)`** percent of all players cheat on at least 3% of questions.
+ How many individual players can you say cheat with a high degree of confidence?
  + Because of how limited this approach is, it's impossible to distinguish between players that certainly and possibly cheat. A core assumption is that no player can overperform in the regular season, so because of how cut and dry that assumption is players that overperform are automatically labeled cheaters. Thus, **`r app1 %>% filter(cheater == 1) %>% nrow()`** players cheat according to this approach. 

## Approach 2

I calculate a "difficulty coefficient" for each question in the first two rounds of 2018 and 2019 by calculating the percentage of correct answers given, and then taking \frac{1}{\text{% Correct}}. This means that difficult questions are weighted more heavily than easy questions. Summing up the "difficulty coefficients" of each question a person gets right indicates how good they are at trivia. Those with higher coeffients are able to answer a larger number of difficult questions. Using this approach, here are the top ten best trivia nerds judging by their performances in the first two rounds.  

```{r echo = FALSE, message = FALSE}
champ_difficulty <- edited %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, round, qno) %>%
  summarize(corr = sum(ans), asked = n()) %>%
  mutate(pct_corr = corr/asked,
         # I let difficulty be 1/pct_corr because I want its value to be higher for questions that people get correct less often.
         difficulty_val = 1/pct_corr) %>%
  select(year, round, qno, pct_corr, difficulty_val)

# Difficult questions are answered correctly a standard deviation less frequently than the mean of each round.
champ_difficulty_metrics <- champ_difficulty %>%
  group_by(year, round) %>%
  summarize(mean_corr = mean(pct_corr), sd = sd(pct_corr))

best_nerds <- edited %>%
  drop_na(honorsystemcorrect) %>%
  filter(ans == 1) %>%
  inner_join(champ_difficulty) %>%
  group_by(name, year, honorsystemcorrect) %>%
  summarize(score = sum (difficulty_val)) %>%
  arrange(desc(score))

best_nerds %>%
  head(10) %>%
  mutate(honorsystemcorrect = percent(honorsystemcorrect, accuracy = 2),
         score = round(score, digits = 3)) %>%
  kable("latex", booktabs = T,
        col.names = c("Name", "Year", "% Correct (Honor Score)", "Difficulty Coeff")) %>%
  kable_styling(position = "center")
```

These are some pretty exceptional players. Note that Ken Jennings floats to the top. The next step is to quantify which questions are uniquely difficult. I calclulate the mean and standard deviation of the correct percentage for each round in each year. Those questions that are 1 standard deviation above or below I denote as easier or harder, respectively. Players that fail easy questions likely cheated. 

```{r echo = FALSE, message = FALSE}
best_nerds %>%
  ggplot(mapping = aes(x = honorsystemcorrect, y = score)) +
  geom_point()

app2 <- champ_difficulty %>%
  left_join(champ_difficulty_metrics) %>%
  mutate(difficulty = if_else(pct_corr > mean_corr + sd, 0, 1),
         difficulty = if_else(pct_corr < mean_corr - sd, 2, difficulty))

ggplot(app2, mapping = aes(x = qno, y = pct_corr, fill = factor(difficulty))) +
  geom_col() +
  geom_hline(app2, mapping = aes(yintercept = mean_corr + sd), color = "#52b36c") +
  geom_hline(app2, mapping = aes(yintercept = mean_corr - sd), color = "#d15656") +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_fill_manual(name = "Question\n   Type",
                    labels = c("Easy", "Medium", "Hard"),
                    values = c("#52b36c", "#6d90c9", "#d15656")) +
  labs(title = "Difficulty of Questions by Round and Year",
       caption = "Source: LearnedLeague",
       x = "Question Number",
       y = "Percent Correct ") +
  facet_grid(round ~ year) +
  theme(legend.direction = "horizontal",
        legend.position = c(0.15, -0.12),
        legend.background=element_blank())

easyqs <- app2 %>%
  filter(difficulty == 0) %>%
  select(year, round, qno)

inner_join(easyqs, edited) %>%
  drop_na(honorsystemcorrect) %>%
  group_by(name, honorsystemcorrect) %>%
  summarize(count = sum(ans)) %>%
  mutate(num_easyqs = nrow(easyqs)) %>%
  arrange(-desc(count))
## being good at trivia means you can answer lots of hard questions.
```

+ What is your estimate of the average percent of questions that are cheated on for the entire group during the regular season?
  + The `y = x` line provides an implicit upper limit on how one can score. If we accept the assumption that each person's championship score is representative of their true ability, then each individual's adjusted regular season score would be their championship score. The mean difference between the regular season and championship accuracy rate approximates the average percent of questions that are cheated on for the entire group during the regular season. That number is **`r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% pull(m) %>% mean(na.rm = TRUE) %>% percent(accuracy = 0.1)`**.
+ What percent of the players do you think cheat on at least 3 percent of the regular season questions? 
  + To find the percent of the players that cheat on at least 3% of the questions, I need to find the number of players who have a championship mean that is not within 3% of their honor system mean. I count `r app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()` individuals who meet this criteria. That means that **`r (((app1 %>% nrow()) - (app1 %>% filter(cheater == 0) %>% nrow()) - (app1 %>% filter(cheater == 1) %>% mutate(m = honorsystemcorrect - pct_rt) %>% filter(m <= 0.03) %>% nrow()))/(app1 %>% nrow())) %>% percent(accuracy = 0.1)`** percent of all players cheat on at least 3% of questions.
+ How many individual players can you say cheat with a high degree of confidence?
  + Because of how limited this approach is, it's impossible to distinguish between players that certainly and possibly cheat. A core assumption is that no player can overperform in the regular season, so because of how cut and dry that assumption is players that overperform are automatically labeled cheaters. Thus, **`r app1 %>% filter(cheater == 1) %>% nrow()`** players cheat according to this approach. 

## Approach 3

```{r}
ttester <- function(current_selection, year_sel) {
  obs <- edited %>%
    filter(round %in% c(1, 2), 
           year == year_sel,
           name == current_selection)
  # Case where people get a perfect score in competition returns no std dev so 
  # do not do a ttest in those situations
  if (sum(obs$ans) == 24) {
    return(1)
  }
  honsyscorr_num <- obs %>%
    magrittr::extract2(1,6)
  pval <- t.test(obs$ans, mu = honsyscorr_num, alternative = "less") %>%
    broom::tidy() %>%
    magrittr::extract2(1, 3)
}

pvals <- edited %>%
  drop_na(honorsystemcorrect, ans) %>%
  distinct(name, year) %>%
  mutate(pvals = map2(name, year, ttester),
         statsig = if_else(pvals < 0.05, 1, 0))

allplayers <- edited %>%
  filter(round %in% c(1, 2)) %>%
  drop_na(honorsystemcorrect, ans) %>%
  group_by(year, name, honorsystemcorrect) %>%
  summarize(pct_rt = mean(ans)) %>%
  left_join(pvals) %>%
  mutate(cheater = if_else(statsig == 1, 1, 0))

# List of people that cheated
cheaters <- allplayers %>%
  filter(statsig == 1)

# List of people that didn't cheat
fairplayers <- allplayers %>%
  filter(statsig == 0) 
```

```{r}
# Point on the far right side scored 95% but scored in competition like someone who scored 80% on the honor system. Use that system to figure out what the predected scores of people should be. 

allplayers %>%
  ggplot(mapping = aes(x = honorsystemcorrect, y = pct_rt, color = factor(cheater))) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_abline(slope = 1.1, intercept = -0.25) +
  geom_text(aes(0.65, 0.70, label = "Y = X"), color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters under Approach 1",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))

adj <- allplayers %>%
  mutate(pred = if_else(cheater == 1, (pct_rt + 0.25)/1.1, honorsystemcorrect))

ggplot(adj, mapping = aes(pred, pct_rt, color = factor(cheater))) +
  geom_abline(slope = 1) +
  geom_abline(slope = 1.1, intercept = -0.25) +
  geom_point() +
  geom_text(aes(0.25, 0.3, label = "Y = X"), color = "black") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_color_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Distribution of Fair Players and Cheaters under Approach 1",
       x = "Percent Correct, Honor System",
       y = "Percent Correct, Championship",
       caption = "Source: LearnedLeague") +
  theme(legend.position = c(0.91, 0.15))

mean(fairplayers$honorsystemcorrect)
mean(fairplayers$pct_rt)
```


```{r}
edited %>%
  filter(merge == "merged") %>%
  group_by(year, round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  ggplot(mapping = aes(x = qno, y = correct_ans/times_asked)) +
  geom_col() +
  facet_grid(round ~ year) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_y_continuous(limits = c(0, 1), labels = label_percent()) +
  labs(title = "Percent of questions correctly answered in Championship", 
       subtitle = "All Players",
       x = "Question Number", 
       y = "% Correctly Answered")

bind_rows(cheaters, fairplayers) %>%
  inner_join(edited) %>%
  filter(round %in% c(1, 2)) %>%
  group_by(year, round, qno, cheater) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  ggplot(aes(x = qno, y = correct_ans/times_asked, group = cheater, fill = factor(cheater))) +
  geom_col(position = "dodge") +
  facet_grid(round ~ year) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_y_continuous(limits = c(0, 1), labels = label_percent()) +
  scale_fill_manual(name = "Player Type", 
                     labels = c("Fair Player", "Cheater"), 
                     values = c("#52b36c", "#d15656")) +
  labs(title = "Percent of questions correctly answered in Championship by Player Type", 
       caption = "Source: LearnedLeague",
       x = "Question Number", 
       y = "% Correctly Answered") +
  theme(legend.direction = "horizontal",
        legend.position = c(0.15, -0.12))
```

```{r}
cheaters %>%
  mutate(honorsystemcorrect = percent(honorsystemcorrect, accuracy = 0.1),
         pct_rt = percent(pct_rt, accuracy = 0.1)) %>%
  slice(1:10) #%>%
#  kable(col.names = c("Year", "Name", "Percent Correct, Honor System", "Percent Correct, Competition", "P-Value"))
```

### Step 2: how difficult the championship questions are relative to the regular season questions for the above group of people

One fairly awful strategy is to calculate mean correctness percentage of all eligible participants at home, and then compare that to the mean correctness percentage of all eligible participants in competition. By eligible, I mean participants that pass the tests I define in step 1. 



One better strategy is to 

```{r}
# Lets find people who I think played honestly during the regular season. 
edited %>%
  distinct(name, honorsystemcorrect) %>%
  ggplot(aes(honorsystemcorrect)) +
  geom_histogram()

edited %>%
  group_by(name, year, round) %>%
  mutate(stdev = sd(ans), competcorrect = mean(ans)) %>%
  mutate(tstatistic = (competcorrect - honorsystemcorrect)/(stdev/sqrt(12)))

```

4. Explain why it is easier or harder to make claims about the aggregate amount of cheating in a sample versus identifying individual cheaters.

5. The players with -99 for honor code scores dropped out of the league after making one or both championships. Can you make any inferences about whether they cheated more or less than the players who have remained in the league, despite the fact you know nothing about their percent correct in the regular season?

I've identified the characteristics of what a cheater looks like, and I think all these people fit the bill based on one axis. Not a single person who stayed who had the same championship scores as the -99ers was categoriesed as a fair player. Thus, I think they are cheaters. 

```{r}
dropouts <- edited %>% 
  filter(is.na(honorsystemcorrect)) %>%
  distinct(name, year) %>%
  pull(name)

x <- edited %>%
  filter(name %in% dropouts) %>%
  group_by(name, year) %>%
  summarize(pct_corr = mean(ans)) %>%
  ungroup() %>%
  count(pct_corr)

ggplot() +
  geom_abline(slope = 1, alpha = 0.25) +
  geom_point(cheaters, mapping = aes(honorsystemcorrect, pct_rt, color = "Cheaters"), alpha = 0.25) +
  geom_point(fairplayers, mapping = aes(honorsystemcorrect, pct_rt, color = "Fair Players"), alpha = 0.25) +
  geom_hline(x, mapping = aes(yintercept = pct_corr), linetype = "longdash") +
  labs(title = "Percent Correct at Home vs Championship by Player Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

6. the person who runs this league is interested in learning your findings. Create one visual that you think best would summarize your insights showing the amount/non-existence of cheating in his league.

```{r, include = FALSE}
edited %>% 
  filter(honorsystemcorrect > 0) %>%
  ggplot(mapping = aes(x = honorsystemcorrect, y = numbercorrect/12)) +
  geom_point(alpha = 0.075, stroke = 0) +
  geom_smooth() +
  scale_y_continuous(labels = label_percent()) +
  scale_x_continuous(labels = label_percent()) +
  labs(x = "% Correct on Honor System", y = "% Correct Live")

edited %>%
  filter(merge == "honorsystem_only") %>%
  ggplot(aes(x = honorsystemcorrect)) +
  geom_histogram()
```

```{r include = FALSE}

edited %>%
  filter(merge == "merged", year == 2018) %>%
  group_by(round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  mutate(percent = percent(correct_ans/times_asked)) %>%
  select(-correct_ans, -times_asked, Round = round) %>%
  arrange(-desc(Round), -desc(qno)) %>%
  mutate(qno = glue("Q {qno}")) %>%
  pivot_wider(id_cols = Round, names_from = qno, values_from = percent) %>%
  kable(booktabs = T, caption = "2018 Percent of Questions Answered Correctly")

edited %>%
  filter(merge == "merged", year == 2019) %>%
  group_by(round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  mutate(percent = percent(correct_ans/times_asked)) %>%
  select(-correct_ans, -times_asked, Round = round) %>%
  arrange(-desc(Round), -desc(qno)) %>%
  mutate(qno = glue("Q {qno}")) %>%
  pivot_wider(id_cols = Round, names_from = qno, values_from = percent) %>%
  kable(booktabs = T, caption = "2019 Percent of Questions Answered Correctly")
```

# Appendices

```{r, warning = FALSE, message = FALSE, echo = FALSE}
champ2018 <- edited %>%
  filter(merge == "merged", year == 2018) %>%
  group_by(year, round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  mutate(percent = percent(correct_ans/times_asked)) %>%
  select(-correct_ans, -times_asked, Round = round) %>%
  arrange(-desc(Round), -desc(qno)) %>%
  mutate(qno = glue("Question {qno}")) %>%
  pivot_wider(id_cols = c(qno, year), names_from = Round, values_from = percent)

champ2019 <- edited %>%
  filter(merge == "merged", year == 2019) %>%
  group_by(year, round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  mutate(percent = percent(correct_ans/times_asked)) %>%
  select(-correct_ans, -times_asked, Round = round) %>%
  arrange(-desc(Round), -desc(qno)) %>%
  mutate(qno = glue("Question {qno}")) %>%
  pivot_wider(id_cols = c(qno, year), names_from = Round, values_from = percent)

size <- edited %>%
  filter(merge == "merged") %>%
  group_by(year, round) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  pull(times_asked)

bind_cols(champ2018, champ2019) %>%
  ungroup() %>%
  select(-year, -year1, -qno1) %>%
  kable("latex", 
        col.names = append("Sample Size (n = )", size), 
        booktabs = T,
        caption = "2018/2019 Championship Percentage Correct by Question") %>%
  add_header_above(c("Round Number", "1", "2", "3", "4", "1", "2", "3", "4")) %>%
  add_header_above(c(" ", "2018" = 4, "2019" = 4)) %>%
  kable_styling(position = "center", latex_options = c("repeat_header"))

edited %>%
  filter(merge == "merged") %>%
  group_by(year, round, qno) %>% 
  summarize(correct_ans = sum(ans), times_asked = n()) %>%
  ggplot(mapping = aes(x = qno, y = correct_ans/times_asked)) +
  geom_col() +
  facet_grid(year ~ round) +
  scale_x_continuous(breaks = seq(1, 12)) +
  scale_y_continuous(labels = label_percent()) +
  labs(title = "Percent of questions correctly answered in Championship", 
       x = "Question Number", 
       y = "% Correctly Answered")

## What were the lifetime honor system averages of people who advanced through each stage of the competition.
# 1212 people did not qualify to the champinonship. 

edited %>%
  group_by(year, round) %>%
  summarize(sample_size = n(), mean_hnr_pct = mean(honorsystemcorrect, na.rm = TRUE)) %>%
  mutate(mean_hnr_pct = percent(mean_hnr_pct, accuracy = 0.1)) %>%
  drop_na() %>%
  mutate(sample_size = glue("(n = {sample_size})")) %>%
  unite(join, c(mean_hnr_pct, sample_size), sep = " ") %>%
  pivot_wider(id_cols = year, names_from = round, values_from = join) %>%
  rename(Year = year) %>%
  kable(booktabs = T, caption = "Percentages of Honor System Success by Round and Year") %>%
  kable_styling(position = "center")

# List of all unique individuals. Is there any overlap between those in the champ and those not in the champ?
#edited %>% select(name, merge) %>% distinct()
```
