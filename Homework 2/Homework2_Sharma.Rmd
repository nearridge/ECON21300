---
title: "Homework 2: Evaluating Randomized Experiments"
author: "Neeraj Sharma"
date: "05/02/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r include = FALSE}
library(tidyverse)
library(magrittr)
library(broom)
library(knitr)
library(ggthemes)
```

## Question 1: Estimate the treatment effect and the associated standard error on the raw data given to you, assuming no issues with the data. 

By definition, the Average Treatment Effect is defined to be $\frac{1}{N}\sum_i y_1(i) - y_0(i)$ where $y_1(i)$ and $y_0(i)$ are the values of the outcome variable (in this case hours exercised) in each treatment scenario. Unfortunately, it is often impractical to utilize this straightforward approach. This formula presumes that one can quantify the outcome of a given individual when treatment is both given and withheld. However, because each individual can only be slotted into one category, this approach cannot be perfectly achieved. 

Thus, a random experiment with a control and treatment group can be conducted to smooth out differences among populations in order to isolate the treatment effect specifically. With large enough sample groups, the difference between the mean of the outcome of the treatment group and mean of the outcome of the control group yields the Average Treatment Effect. 

Here are the relevant summary statistics of the data set without any modification. 

```{r message=FALSE}
# Read in the raw data. 
raw <-  read_csv("problem_set2.csv")

# Create dataframe with summary statistics for hours
unclean_data_summary <- raw %>%
  group_by(treatment) %>%
  summarize(count = n(), mean(hours), sd(hours))

# Kable print unclean_data
unclean_data_summary %>%
  knitr::kable(col.names = c("Treatment", "Count", "Mean", "St Dev"), 
        caption = "Summary of Hours Exercised, No Data Cleaning")

unclean_data_model <- lm(hours ~ treatment, data = raw) %>% 
  tidy()

unclean_data_model %>%
  kable(col.names = c("Term", "Coeff Estimate", "Standard Error", "T-Stat", "P-Val"), caption = "Summary of Linear Model, No Clean")
```

The mean hours exercised for individuals in the treatment group is `r unclean_data_summary %>% extract(2, 3)` and the mean hours exercised for individuals in the non-treatment group is `r unclean_data_summary %>% extract(1, 3)`. Assuming randomness was properly implemented in this study, the difference between these two numbers will be the Average Treatment Effect of the treatment based on the analysis I provide above. Thus, the Average Treatment Effect is **`r unclean_data_model %>% extract2(2, 2)`** with a standard error of **`r round(unclean_data_model %>% extract2(2, 3), digits = 4)`**.

## Question 2: It’s always a good idea to check a data set for errors. Clean this data set as you think appropriate. As an answer to this question, note all the kinds of changes you made to the data, a few words explaining your reason for the change, and which observations you changed (noting the observation number included as a variable in the data set for identification purposes).  If it is totally obvious which observations you changed and there are a large number in the category (e.g. if you decided to drop all White study participants), you can just note what you did for that change (“I dropped all white participants”) and explain why. 

I noticed several types of data errors and compiled a representative sample of troubled observations here.

```{r}
raw %>% 
  filter(subject_id %in% c(1, 9, 16, 26, 31, 52, 65, 100, 103)) %>%
  kable(caption = "Representative sample of unclean observations")
```

Given these errors, I perform the following modifying operations to clean the data set. See appendices for the specific code I use to accomplish these modifications.

```{r}
tibble(
  Variable = append(names(raw), "changed?"),
  `Description of Modification` = c(
    "No change",
    "Hours over 60 are minutes; reformatted to be hours.",
    "No change.",
    "All variant spellings recoded to \"Woodlawn\" and \"Hyde Park.\"",
    "0/1/male/female recoded uniformly as 0/1.",
    "-99 means missing age data; recoded to be NA.",
    "BMIs of less than 1 have undetermined error; recoded to be NA.*",
    "No change.",
    "Race/Ethnicity \"BLACK\" capitalization recoded to \"Black.\"",
    "`changed?` notes and counts changes that occurred in cleaning an observation."
  )
) %>%
  knitr::kable()
```

*The source of error on BMI is very difficult to determine. There are multiple hypotheses I have for the questionable data. It could be an error in data entry where the decimal was misplaced in which case multiplying by 100 would resolve the issue. It could be that the data was entered in a different unit than normal (pounds vs kilograms or meters vs feet) and the application of the BMI formula resulted in very low numbers. It is impossible to certify which error occurred, if any, so the safest option is to ignore these `r nrow(raw %>% filter(bmi < 1))` rows. This is a small enough number that it will not significantly harm my interpretation. 

```{r}
# Clean the data to impose uniformity upon the variable encoding.  
clean_data <- raw %>%
  mutate(`changed?` = seq(1, 1000) * 0) %>%
  # Fixing messed up hours readings. They start at 60 and upwards and that's 1 hr so I
  # fix based on that.
  mutate(`changed?` = if_else(hours >= 60, `changed?` + 1, `changed?`),
         hours = if_else(hours >= 60, hours / 60, hours)) %>%
  mutate(`changed?` = if_else(community_center %in% c("WOODLAWN",
                                                      "hyde park",
                                                      "woodlawn",
                                                      "Hyd Park",
                                                      "HYDE PARK",
                                                      "Hyde_Park",
                                                      "HYDE_PARK",
                                                      "hyde_park"), 
                              `changed?` + 1, `changed?`),
         community_center = if_else(community_center %in% c("WOODLAWN", "woodlawn"),
                                    "Woodlawn", community_center),
         community_center = if_else(community_center %in% c("hyde park", 
                                                            "Hyd Park", 
                                                            "HYDE PARK", 
                                                            "HYDE_PARK", 
                                                            "hyde_park",
                                                            "Hyde_Park"), 
                                    "Hyde Park", community_center)) %>%
  # Recoding female variable to be factor categorical variable from 0/1/male/female.
  mutate(`changed?` = if_else(female %in% c("female", "male"), 
                              `changed?` + 1, `changed?`),
         female = as.double(if_else(female == "female", 
                                    "1", if_else(female == "male", "0", female)))) %>%
  # -99 is missing age data so I reincode it at missing age data. 
  # https://cran.r-project.org/web/packages/naniar/vignettes/replace-with-na.html
  mutate(`changed?` = if_else(age == -99, `changed?` + 1, `changed?`), 
         age = na_if(age,-99)) %>%
  # Currently I have removed improper values, but I could also justify multiplying by 10.
  mutate(`changed?` = if_else(bmi < 1, `changed?` + 1, `changed?`),
         bmi = ifelse(bmi < 1, NA, bmi)) %>%
  # Fix all BLACK observations to normal capitalization structure.
  mutate(`changed?` = if_else(is.na(race_ethnicity), 
                              `changed?`, if_else(race_ethnicity == "BLACK", 
                                                  `changed?` + 1, `changed?`)),
    race_ethnicity = if_else(is.na(race_ethnicity), 
                             race_ethnicity, str_to_sentence(race_ethnicity))) # %>%
# mutate(race_ethnicity = factor(race_ethnicity, c("Black", "Hispanic", "White"))) %>%
# mutate(treatment = factor(treatment, labels = c("No Treatment ($0)", "Treatment ($10)"))) %>%
# mutate(community_center = factor(community_center, labels = c("Woodlawn", "Hyde Park"))) %>%
# mutate(education = factor(education, levels = c("less than high school",
#                                                 "high school",
#                                                 "higher degree")))
```

## Question 3: With your cleaned data set, re-estimate the treatment effect and estimated standard error, assuming the randomization worked fine. 

```{r}
# Create dataframe with summary statistics for hours
clean_data_summary <- clean_data %>%
  group_by(treatment) %>%
  summarize(count = n(), mean(hours), sd(hours))

# Kable print unclean_data
clean_data_summary %>%
  knitr::kable(col.names = c("Treatment", "Count", "Mean", "St Dev"), 
        caption = "Summary of Hours Exercised, Data Cleaned")

clean_data_model <- lm(hours ~ treatment, data = clean_data) %>% 
  tidy()

clean_data_model %>%
  kable(col.names = c("Term", "Coeff Estimate", "Standard Error", "T-Stat", "P-Val"), caption = "Summary of Linear Model, Clean")
```

The mean number of hours exercised in both the treatment and control groups has fallen dramatically upon cleaning the data. Numerous entries were coded in minutes instead of hours and those observations were dragging the values up significantly. Those errors have since been corrected. Thus, the Average Treatment Effect upon cleaning the data yet assuming proper randomization is is **`r clean_data_model %>% extract2(2, 2)`** with a standard error of **`r round(clean_data_model %>% extract2(2, 3), digits = 4)`**.

## Question 4: Evaluate whether the randomization appears legitimate. If not, what is your evidence? (Hint: something went wrong.)

An important piece of insight I gained from Eric's office hours were that given a sufficiently large sample size, perfect random assignment means by definition that one could randomly subdivide the data into equally sized groups of people and the distribution of the covariates should be the same. Thus, if I were to create histograms of some of the specified covariates in this data set like BMI, age, race, or community, I should observe similar distributions and summary statistics to justify the representatives and randomness of the allocation of the sample groups. Eric noted that on this problem set specifically is straightforward enough with regards to the identification of systematic differences that imply a non-random allocation that full t-test would not be necessary.

```{r}
randomness <- clean_data %>%
  mutate(treatment = factor(treatment, labels = c("No Treatment ($0)", "Treatment ($10)"))) %>%
  mutate(race_ethnicity = factor(race_ethnicity, c("Black", "Hispanic", "White"))) %>%
  mutate(community_center = factor(community_center, labels = c("Hyde Park", "Woodlawn"))) %>%
  mutate(education = factor(education,levels = c("less than high school", "high school", "higher degree")))

randomness %>% 
  select(treatment, community_center) %>% 
  group_by(community_center, treatment) %>% 
  count() %>%
ggplot(mapping = aes(x = community_center, y = n, label = n)) +
  geom_col(fill = "#0090d3", color = "black") +
  geom_text(nudge_y = -15, fontface = "bold", color = "White") +
  labs(x = "Community Center", y = "Count", title = "Treatment by Location") +
  theme_economist() +
  scale_fill_economist() +
  facet_wrap(~ treatment)
```

This plot clearly shows a bias in the group allocations based on survey site. Were this data to be randomly created, we would expect to see an even distribution of individuals in the treatment and non-treatment groups across Woodlawn and Hyde Park. Instead, we find a disproportionate amount of the control group was assigned at Hyde Park and conversely, a disproportionate number of people in the treatment group were assigned in Woodlawn. A random experiment would not exhibit this property.

Further analysis on other covariates supports the conclusion that race is not controlled between treatment groups. 

```{r warning = FALSE}
randomness %>%
  group_by(community_center, treatment, race_ethnicity) %>%
  drop_na(race_ethnicity) %>%
  count() %>%
  ggplot(mapping = aes(x = community_center, y = n, fill = race_ethnicity, label = n)) +
  geom_col(position = "stack", color = "black") +
  geom_text(position = "stack", vjust = 1.2, fontface = "bold", color = "white") +
  theme_economist() +
  theme(legend.position = "bottom", legend.key.width = unit(0.4, "cm"), legend.key.height = unit(0.4, "cm"), legend.text = element_text(size = 11)) +
  scale_fill_economist(name = "Race") +
  labs(x = "Community Center", y = "Count", title = "Treatment by Location and Race") +
  facet_wrap(~ treatment)

# theme(legend.position = "bottom", legend.key.height = unit(0.2, "cm"), legend.key.width = unit(0.3, "cm"), legend.box.spacing = unit(0.01, "cm")) +
```

The third and final variable I perform significant analysis on to understand the pattern of randomness is BMI. 

```{r warning = FALSE, fig.height = 3.5}
mean_bmi <- randomness %>% 
  group_by(treatment) %>% 
  summarize(mean(bmi, na.rm = TRUE)) %>%
  mutate(`mean(bmi, na.rm = TRUE)` = round(`mean(bmi, na.rm = TRUE)`, digits = 3))

randomness %>% 
  ggplot(aes(x = bmi, fill = "#0090d3")) + 
  geom_histogram(position = "dodge", color = "black", fill = "#0090d3", bins = 13) +
  geom_vline(mean_bmi, mapping = aes(xintercept = `mean(bmi, na.rm = TRUE)`), 
             show.legend = FALSE, size = 1, color = "#c44751") +
  geom_text(mean_bmi, nudge_x = -7, mapping = aes(x = `mean(bmi, na.rm = TRUE)`, y = 110, 
                                    label = paste("Mean: ", `mean(bmi, na.rm = TRUE)`))) +
  theme_economist() +
  theme(legend.position = "none") +
  labs(title = "Distribution of BMIs given Treatment Group") +
  facet_wrap(~ treatment)
```

There is an apparent difference between the mean BMI in the treatment and non-treatment group, but it is unclear if it is significant enough to warrant inclusion as a source of failed randomization. A simple T-Test can shed more light.

```{r}
ttest <- t.test(bmi ~ treatment, data = randomness) %>%
  tidy() %>%
  mutate(p.value = as.character(round(p.value, digits = 10))) %>%
  select(-method)

ttest %>%
  kable()
```

The T-Test reveals that there is a statistically significant difference between the means of the two sample groups given the p-value of `r ttest %>% extract2(1, 5)`. 

Plots of other covariates imply that those variables were properly randomized. For instance, the plot for education visually provides evidence for an even distribution of education levels throughout the community centers and test groups.  

```{r}
randomness %>%
  group_by(treatment, education, community_center) %>%
  count() %>%
  ggplot(mapping = aes(x = community_center, y = n, fill = fct_reorder(education, -n), label = n)) +
  geom_col(position = "stack", color = "black") +
  geom_text(position = "stack", vjust = 1.2, fontface = "bold", color = "white") +
  theme_economist() +
  theme(legend.position = "bottom", legend.key.width = unit(0.4, "cm"), legend.key.height = unit(0.4, "cm"), legend.text = element_text(size = 11)) +
  scale_fill_economist(name = "Education") +
  labs(x = "Community Center", y = "Count", title = "Treatment by Location and Race") +
  facet_wrap(~ treatment)
```

For brevity, I only provide summary statistics to articulate this point further:

```{r warning = FALSE, message = FALSE}
a <- randomness %>% 
  group_by(treatment) %>% 
  summarize(`Mean Female` = mean(female, na.rm = TRUE), 
            `Mean Age` = mean(age, na.rm = TRUE))
b <- randomness %>%
  group_by(treatment, education) %>%
  summarize(count = n()) %>%
  pivot_wider(treatment, names_from = education, values_from = count)

left_join(a, b) %>%
  kable(caption = "Summary of random covariates")
```

## Question 5: Offer your best hypothesis/hypotheses as to what went wrong with the randomization? What evidence do you have to support your hypothesis(es)? For each of these hypotheses, describe your best strategy for estimating a plausible treatment effect, in spite of the bad randomization. (But don’t actually estimate that treatment effect.)

My hypothesis is that Justin was trigger happy with his treatment assignments because he was stationed at the Woodlawn community center which is over represented in the treatment group. Question 4 provides a hint indicating that something "went wrong" in the data collection process. This implies that there was a material mistake in the collection separate from random variance in the population that might skew covariates in one direction or the other. The number of observations taken from each sample site is something that is in Eric and Justin's control, so I believe that this error is the thing that "went wrong" and is the source of the error in randomization.

The evidence I have collected to support this hypothesis is the chart I produce above as well as the following t-test which rejects the two-tailed null hypothesis that the means are equal. 

```{r}
fittingd <- randomness %>%
  mutate(community_center = as.numeric(community_center) - 1,
         treatment = as.numeric(treatment) - 1,
         education = as.numeric(education),
         # Dummy variables for education
         # High school is reference variable because it is most normative value in this dataset
         mhs = if_else(education == 3, 1, 0),
         lhs = if_else(education == 1, 1, 0),
         # Dummy variables for race. 
         # Black is the reference variable because it is the most normative value of race in this data set
         hispanic = if_else(race_ethnicity == "Hispanic", 1, 0),
         hispanic = replace_na(hispanic, 0),
         white = if_else(race_ethnicity == "White", 1, 0),
         white = replace_na(white, 0),
         NArace = if_else(is.na(race_ethnicity), 1, 0)) %>%
  select(-race_ethnicity, -education) %>%
  drop_na(bmi)

t.test(community_center ~ treatment, data = fittingd) %>%
  tidy() %>%
  select(-method) %>%
  kable()
```

Furthermore, I hypothesize that the differences in race and BMI are also side effects of this incorrect sampling. As far as race goes, Hyde Park has the University of Chicago which dramatically alters the racial mixture of the south-side neighborhood. Most University affiliates are white, and most live in Hyde Park, so it makes sense that the Hyde Park neighborhood will have a significantly higher number of white individuals sampled compared to Woodlawn. 

Secondly, I have absolutely zero evidence to back this up, but my gut is that Hyde Park has a lower average BMI than Woodlawn due to population differences in terms of primarely income. I have not explored this avenue however, so I would like to place a significant caveat on this point. No matter what, both race and BMI are attributes that are intrinsic to the neighborhoods but are also important to control for. 

My strategy to control for the community center, race, and BMI data is to simply do a multiple linear regression across those, plus the independent treatment variable. I have coded dummy variables for race and community center as those are the primary categoricals I will be analyzing. 

## Question 6: Given your answer to question five come up with your best estimate of the true treatment effect in the experiment as well as its standard error.

```{r}
fit1 <- lm(hours ~ treatment, data = fittingd)
fit2 <- lm(hours ~ treatment + community_center, data = fittingd)
fit3 <- lm(hours ~ treatment + community_center + hispanic + white, data = fittingd)
fit4 <- lm(hours ~ treatment + community_center + hispanic + white + bmi, data = fittingd)

anova(fit1, fit2, fit3, fit4) %>%
  kable(col.names = c("Degrees of Freedom", "Residual Sum of Squareds", "delta DF", "Sum of Squares", "F Statistic", "Pr (> F)"))
```

Comparing the models confirms that a model with treatment, community center, race, and bmi is meaningfully more accurate than any other given the randomness and treatment type, I proceed with that as my model. 

```{r}
final <- fit4 %>%
  augment() %>%
  group_by(treatment) %>%
  summarize(count = n(), mean(.fitted), sd(.fitted)) 

final %>%
  knitr::kable(col.names = c("Treatment", "Count", "Mean", "St Dev"), 
        caption = "Summary of Hours Exercised, Pure Treatment Effect")

final_model <- fit4 %>%
  tidy()

final_model %>% kable(col.names = c("Term", "Coeff Estimate", "Standard Error", "T-Stat", "P-Val"), caption = "Summary of Linear Model, Adjusted Randomness")
```

After all this, the average treatment effect calculated after adjusting for errors in randomness and corresponding covariates is **`r round(final_model %>% extract2(2, 2), digits = 4)`** and the standard error on that treatment effect is **`r round(final_model %>% extract2(2, 3), digits = 4)`**.

Furthermore, the low p-value associated with this statistic means that it is essentially 0 probability that the treatment effect we observe happens accidentally. The p-value is determined by the t-value which is determined by the Standard Error, so this is compelling. 

## Appendices

### Code to clean data in question 2

```{r echo = TRUE}
# Clean the data to impose uniformity upon the variable encoding.  
clean_data <- raw %>%
  mutate(`changed?` = seq(1, 1000) * 0) %>%
  # Fixing messed up hours readings. They start at 60 and upwards and that's 1 hr so I
  # fix based on that.
  mutate(`changed?` = if_else(hours >= 60, `changed?` + 1, `changed?`),
         hours = if_else(hours >= 60, hours / 60, hours)) %>%
  mutate(`changed?` = if_else(community_center %in% c("WOODLAWN",
                                                      "hyde park",
                                                      "woodlawn",
                                                      "Hyd Park",
                                                      "HYDE PARK",
                                                      "Hyde_Park",
                                                      "HYDE_PARK",
                                                      "hyde_park"), 
                              `changed?` + 1, `changed?`),
         community_center = if_else(community_center %in% c("WOODLAWN", "woodlawn"),
                                    "Woodlawn", community_center),
         community_center = if_else(community_center %in% c("hyde park", 
                                                            "Hyd Park", 
                                                            "HYDE PARK", 
                                                            "HYDE_PARK", 
                                                            "hyde_park",
                                                            "Hyde_Park"), 
                                    "Hyde Park", community_center)) %>%
  # Recoding female variable to be factor categorical variable from 0/1/male/female.
  mutate(`changed?` = if_else(female %in% c("female", "male"), 
                              `changed?` + 1, `changed?`),
         female = as.double(if_else(female == "female", 
                                    "1", if_else(female == "male", "0", female)))) %>%
  # -99 is missing age data so I reincode it at missing age data. 
  # https://cran.r-project.org/web/packages/naniar/vignettes/replace-with-na.html
  mutate(`changed?` = if_else(age == -99, `changed?` + 1, `changed?`), 
         age = na_if(age, -99)) %>%
  # Currently I have removed improper values, but I could also justify multiplying by 10.
  mutate(`changed?` = if_else(bmi < 1, `changed?` + 1, `changed?`),
         bmi = ifelse(bmi < 1, NA, bmi)) %>%
  # Fix all BLACK observations to normal capitalization structure.
  mutate(`changed?` = if_else(is.na(race_ethnicity), 
                              `changed?`, if_else(race_ethnicity == "BLACK", 
                                                  `changed?` + 1, `changed?`)),
    race_ethnicity = if_else(is.na(race_ethnicity), 
                             race_ethnicity, str_to_sentence(race_ethnicity))) # %>%
# mutate(race_ethnicity = factor(race_ethnicity, c("Black", "Hispanic", "White"))) %>%
# mutate(treatment = factor(treatment, labels = c("No Treatment ($0)", "Treatment ($10)"))) %>%
# mutate(community_center = factor(community_center, labels = c("Woodlawn", "Hyde Park"))) %>%
# mutate(education = factor(education, levels = c("less than high school",
#                                                 "high school",
#                                                 "higher degree")))
```

```{r}
# mean_ages <- randomness %>% group_by(treatment) %>% summarize(mean(age, na.rm = TRUE))
# mean_ages
# 
# randomness %>% 
#   group_by(treatment) %>% 
#   count(age) %>% 
#   ggplot(aes(x=age, y=n, fill = treatment)) + 
#   geom_col(position = "dodge") +
#   geom_vline(mean_ages, mapping = aes(xintercept = `mean(age, na.rm = TRUE)`, color = treatment)) +
#   theme_economist() +
#   labs(title = "Mean age of participant in each group to prove randomness. Means are similar.")
# 
# t.test(bmi ~ treatment, data = fittingd)
# t.test(treatment ~ community_center, data = fittingd)

```
